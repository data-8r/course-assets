{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating an RCT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the final lab!\n",
    "\n",
    "In today's lab, we'll replicate some results from a recent randomized controlled experiment.\n",
    "\n",
    "In the Second Liberian Civil War, which lasted from 1999 to 2003, many children were recruited as soldiers.  By 2009, many of these ex-fighters were working in illegal industries or as mercenaries.\n",
    "\n",
    "An organization called Action On Armed Violence wanted to know whether a program of training and monetary aide could help ex-fighters reintegrate into Liberian society.  Such programs have had mixed results in other contexts, but most of the available evidence was from observational studies, not RCTs.  They identified a candidate group of ex-fighters, randomly assigned them to treatment and control groups, and offered their assistance program to the treatment group.\n",
    "\n",
    "Our goal is to determine whether the assistance program actually improved outcomes for the people in the experiment.\n",
    "\n",
    "The data are available [here](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/11R0LX&version=2.1) and the paper [here](https://www.povertyactionlab.org/sites/default/files/publications/994_138_Can-Employment-Reduce-Lawlessness-and-Rebellion_June2015.pdf).  The data come straight from the first link; we haven't modified them at all.\n",
    "\n",
    "You should also be aware that there are many additional questions that go into the design and analysis of an RCT.  For example, some of the people in the experimental group declined to participate, which could become a confounding factor in the analysis if not handled properly.  (Why?)  Many details like that are discussed in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up the notebook, but please don't change it.\n",
    "\n",
    "# These lines import the Numpy and Datascience modules.\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "# These lines load the tests.\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('lab15.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to load the data in a table called raw.  **Do not attempt to look at the table.**  It has so many columns that your browser may crash!  If you want, you can use `raw.labels` to see a list of the columns in the table.  `sorted(raw.labels)` will show them sorted in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install zip\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"aoav.zip\", 'r') as f:\n",
    "    f.extractall(\".\")\n",
    "    print(\"Successfully extracted dataset.\")\n",
    "raw = Table.read_table(\"analysis_final.tsv\", sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "The `raw` table presents a few challenges.  We should clean it up a bit before we proceed.  Here are some problems:\n",
    "\n",
    "1. There are thousands of columns in the table, which makes the table difficult to read.  For our analysis, we're going to look only at two of those columns:\n",
    "  * `assigned_final`: Whether the person was in the treatment or the control group.  1 means treatment, and 0 means control.\n",
    "  * `raiseanintfut_dum_end`: Whether the person expressed interested in raising animals at the end of the trial period.  1 means they expressed interest, and 0 means they didn't.  (`\"raiseanintfut\"` is short for \"raise animals in the future.\"  `\"dum\"` is short for \"dummy,\" which just means the variable is coded as 0 or 1.  `\"end\"` means the variable was measured at the end of the experiment.)\n",
    "\n",
    "2. Some of the people didn't report their interest.  Their `raiseanintfut_dum_end` are labeled as `nan`, which stands for \"not a number.\"  This will cause a problem for any analysis of that column.  They can be removed by choosing only rows where `raiseanintfut_dum_end` is greater than or equal to 0.\n",
    "\n",
    "3. The existing column names are terrible.  They should be called `\"Treatment\"` and `\"Interested in raising animals\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Produce a table called `farming` that is a cleaned-up version of `raw`.  You should address all three of the issues described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "farming = ...\n",
    "              ...\n",
    "              ...\n",
    "              ...\n",
    "farming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Find the proportion of people interested in raising animals in the treatment and control groups.  **Find a way to produce a table containing these values with a single call to the `group` method.**  Name your table `proportions`.\n",
    "\n",
    "*Hint:* If two people are 1s and three are 0s, then .2 of the people are 1s.  That's also the *average* of the array [1, 1, 0, 0, 0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions = ...\n",
    "proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "What pattern do you observe in the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is there really an effect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individuals were assigned randomly to the treatment and control groups.  It is therefore possible that the pattern you described is due to chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Define appropriate null and alternative hypotheses that you could test to guard against this possibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "You should be able to test your null hypothesis by repeatedly taking samples of a certain size from `farming`.  What size should that be?  Calculate it using Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = ...\n",
    "sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Now that we've determined the sample size, how can we go about create many many simulations? One approach is to create 1 sample at a time, and then compute the test statistic for that sample. Write the function `sample_once` below! Suppose that you've got a `test_statistic_function`, which is a function that computes the test statistic, and a `sample_size`, which is an integer that specifies how large we want our sample to be. \n",
    "\n",
    "Think about whether you want to sample the `farming` table with or without replacement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_once(sample_size): \n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "We're one step closer to simulating our data! Now let's define a `test_statistic_function` function that we can provide as an input to `sample_once`! Think about what `test_statistic_function` should be able to take in as an input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write your test_stat function here! Make sure to call it test_stat, or the tests will fail!\n",
    "...\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(test_statistic_function(farming), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "We're down to the very last step! We've now got to do our simulations. Let's define a function called `show_null_test_stats` that conducts `num_simulations` of `sample_size`. It should then use the results of the simulations in order to create a histogram.  \n",
    "\n",
    "If your having trouble with this, take a look at the previous lectures, or take look at the extra section 8 worksheet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_null_test_stats(num_simulations, sample_size):\n",
    "    trys = ...\n",
    "    simulations = ...\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Let's take a look at the histogram. What can you conclude? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_null_test_stats(10000, sample_size)\n",
    "plt.scatter(test_statistic_function(farming), 0, color='red', s=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down you conclusion here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once.\n",
    "_ = ok.grade_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to submit your work.\n",
    "# You can submit as many times as you want.  If you want us to grade a\n",
    "# submission other than your most recent one, you can choose which submission\n",
    "# is graded at https://okpy.org/cal/data8r/su17/ .\n",
    "\n",
    "_ = ok.submit()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

